{\rtf1\ansi\ansicpg1252\cocoartf2867
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 import torch\
from peft import PeftModel\
from transformers import AutoModelForCausalLM, AutoTokenizer\
\
BASE_MODEL   = "meta-llama/Llama-3.2-1B-Instruct"\
ADAPTER_PATH = "/home/Fine Tuning Files/final_model"\
MERGED_PATH  = "/home/Fine Tuning Files/merged_model"\
\
# Load tokenizer\
print("Loading tokenizer...")\
tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\
\
# Load base model in float16 for merging\
print("Loading base model...")\
base_model = AutoModelForCausalLM.from_pretrained(\
    BASE_MODEL,\
    torch_dtype=torch.float16,\
    device_map="auto",\
)\
\
# Load LoRA adapters\
print("Loading LoRA adapters...")\
model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\
\
# Merge adapters into base model\
print("Merging adapters...")\
merged_model = model.merge_and_unload()\
\
# Save merged model\
print("Saving merged model...")\
merged_model.save_pretrained(MERGED_PATH, safe_serialization=True)\
tokenizer.save_pretrained(MERGED_PATH)\
\
print(f"\uc0\u9989  Merged model saved to: \{MERGED_PATH\}")\
print("\uc0\u55357 \u56960  Ready to upload to Hugging Face!")}